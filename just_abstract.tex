\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\title{Large Language Models as Syntactic Annotation Labelers for Logical Information Retrieval}
\author{Greg Coppola\\coppola.ai}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    This paper presents what we believe is a novel research question: can \emph{large language models} act as \emph{linguists} to facilitate \emph{open-domain semantic parsing}?
    Open-domain semantic parsing would allow a new kind of information retrieval based on \emph{logical proofs}, and would be highly valuable, but has historically been rate-limited by the cost and reliability of \emph{human syntactic annotations}.
    We present a careful review of past results---as well as important \emph{new} results---that together show that LLMs \emph{can} reliably perform syntactic annotation, but that this ability is highly dependent on the choice of \emph{prompt}.
    We analyze past findings that LLMs cannot act as zero-shot CoNLL dependency parsers, and present a novel analysis as to why, based on the computational complexity of dependency parsing.
    We also present several novel experimental results further showing that LLMs \emph{can} act reliably as linguists, especially in tasks closely related to \emph{semantic parsing}.
    The performance level of the LLM appears comparable to that of a human annotator.
    We believe these results suggest that full open-domain semantic parsing should be possible, given the right \emph{agentic} control flow---that is, a sequence of calls to LLMs and other tools---thus unlocking a new kind of \emph{logical} information retrieval.
\end{abstract}

\end{document}