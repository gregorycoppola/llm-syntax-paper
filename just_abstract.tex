\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{titlesec}
\usepackage{booktabs}
\usepackage{array}

\geometry{margin=1in}

\title{Large Language Models as Syntactic Annotation Labelers for Logical Information Retrieval}
\author{Greg Coppola\\coppola.ai}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    This paper presents a novel research question---can {\em large language models} act as {\em linguists} so as to facilitate {\em open-domain semantic parsing}.
    Open-domain semantic parsing would allow a new kind of information retrieval based on {\em logical proofs}, and thus it would be very valuable if LLM's can be leveraged for this task.
    We present a careful review of past results that shows that LLM's {\em can} act reliably annotate syntactic annotations, but that this ability is highly dependent on the {\em prompt}.
    We analyze past findings that LLM's can {\em not} act as zero-shot CoNLL dependency parsers, and present a novel analysis as to why.
    We present several positive novel experimental results showing further that LLM's {\em can} act reliably as linguists, especially in tasks that are closely related to {\em semantic parsing}.
    We believe that in several cases this is human-level performance on these tasks.
    We propose that these results constitute that full open-domain semantic parsing should be possible, given the right {\em agentic} control flow---aka. sequence of calls to LLM's and other tools---thus unlocking a new kind of {\em logical} information retrieval.
\end{abstract}
\end{document} 