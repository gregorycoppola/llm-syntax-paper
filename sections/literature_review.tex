% Literature review section content will go here 
Recent work has explored the ability of large language models (LLMs) to serve as syntactic annotators, generating linguistic labels such as part-of-speech (POS) tags, dependency trees, and constituency parses. These models can operate in zero-shot, few-shot, or fine-tuned settings, and have shown varying degrees of success depending on the syntactic task, language, and model scale.

\subsection{POS Tagging and Shallow Syntax}

\citet{blevins2023llmpos} examined GPT-3 and GPT-J models on POS tagging, NER, and chunking tasks. Few-shot prompting with GPT-J 6B reached 79\% accuracy for POS tagging, with GPT-3 (175B) scoring slightly lower. While this lags behind traditional supervised taggers (\textasciitilde96\%), it demonstrates the models' internalized syntactic knowledge.

\citet{lai2023chatgptpos} used zero-shot prompting with ChatGPT across 17 languages. Using prompts in either English or the target language, they achieved average POS accuracy of 84--85\%, outperforming fine-tuned XLM-R in most languages.

\citet{machado2024portpos} evaluated GPT-3, LLaMA-7B, and a Brazilian Portuguese LLM on POS tagging. With 10-shot prompts, GPT-3 achieved 90\% accuracy, significantly outperforming the smaller models.

\subsection{Agentic Prompting for Translation Tasks}

Building on a growing body of work that explores large language models (LLMs) as agentic linguistic annotators \citep[e.g.,][]{lai2023chatgptpos, blevins2023llmpos}, \citet{jiao2024gradable} investigate the extent to which LLMs can behave as adaptive agents in machine translation tasks. Rather than retraining or fine-tuning models, their approach leverages prompt engineering to steer ChatGPT's translation outputs across a continuum of linguistic complexity and context awareness.

They introduce the \textbf{T3S taxonomy}, which categorizes translation prompts into five levels of increasing detail and linguistic guidance. The dimensions of this taxonomy—expression type, translation style, part-of-speech (POS) information, and few-shot examples—mirror the types of scaffolding used in syntactic annotation tasks. At higher levels (e.g., Level 4), prompts ask ChatGPT to revise and proofread its own output, encouraging self-monitoring behavior akin to agentic reasoning.

Experimental results on the FLORES-101 Chinese--English corpus show a strong correlation between prompt complexity and translation quality, as measured by BLEU, ROUGE, and human evaluation. Notably, Level 4 prompts outperform even GPT-4's zero-shot baseline. These findings suggest that translation quality can be significantly improved through carefully structured, linguistically informed prompts—demonstrating the capacity of LLMs to act as agentic language processors even in high-level tasks like translation.

\subsection{Constituency Parsing}

\citet{bai2023llmconst} tested GPT-3.5, GPT-4, and LLaMA models on English constituency parsing. GPT-4 achieved an F1 of 73 with five-shot prompting, while open-weight LLaMA models scored below 30 F1.

\citet{tian2024chunkprompt} introduced a chunk-then-parse prompting approach using chain-of-thought (CoT) reasoning. This improved GPT-4's parsing quality on English and Chinese datasets, recovering deeper tree structures.

\subsection{Dependency Parsing}

\citet{hromei2024udllama} fine-tuned LLaMA-2 models on UD data across 26 languages. Their 13B model achieved \textasciitilde93--94\% UAS, rivaling traditional biaffine parsers. Even the 7B model performed competitively.

Conversely, \citet{dubey2025zeroshotdep} found that most LLMs failed in zero-shot dependency parsing. Only LLaMA-70B marginally outperformed trivial baselines such as left-branching.

\subsection{Summary of Methods and Trends}

\begin{table}[ht]
\centering
\begin{tabular}{p{3.3cm} p{2cm} p{2cm} p{2.5cm} p{3.5cm}}
\toprule
\textbf{Study} & \textbf{Model} & \textbf{Task} & \textbf{Method} & \textbf{Result / Remark} \\
\midrule
Blevins et al. (2023) & GPT-3, GPT-J & POS, Chunk & Few-shot & Up to 79\% POS (GPT-J); below SOTA \\
Lai et al. (2023) & ChatGPT & POS (UD) & Zero-shot & Avg. 85\% accuracy (17 langs) \\
Machado \& Ruiz (2024) & GPT-3 & POS (PT-BR) & Few-shot & 90\% POS accuracy \\
Jiao et al. (2024) & ChatGPT & Translation & T3S Taxonomy & Level 4 prompts beat GPT-4 baseline \\
Bai et al. (2023) & GPT-4, LLaMA & Constituency & Few-shot & GPT-4: 73 F1; LLaMA: $<$30 F1 \\
Tian et al. (2024) & GPT-4, GPT-3.5 & Constituency & Chunk + CoT & Improved tree depth and quality \\
Hromei et al. (2024) & LLaMA-2 (13B) & Dependency & Fine-tuned & 93--94\% UAS (26 langs) \\
Dubey et al. (2025) & GPT-4, LLaMA-70B & Dependency & Zero-shot & Often $<$ baseline \\
\bottomrule
\end{tabular}
\caption{LLMs for syntactic annotation: task, model, method, and performance summary.}
\label{tab:llm_syntax}
\end{table}

These studies demonstrate that LLMs can approximate human-level syntactic annotation, particularly for POS tagging. However, performance in parsing (especially full dependency trees) remains variable without fine-tuning. Prompt design, instruction tuning, and model scale all contribute to improved results, and multilingual evaluation remains a critical benchmark for future progress.


