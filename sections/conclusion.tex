\label{sec:conclusion}
We have shown through a mix of past evidence and new results that large language models {\em can} in fact act reliably as linguists, especially with regards to the kinds of syntactic labeling tasks that would be required to do open-domain semantic parsing.

We have specifically shown that for the specific difficult case of {\em prepositional phrase attachment}, that a ``zero shot'' LLM performance is comparable to that of a human, and far beyond that of the Stanford Stanza parser, which we take to be a representation of the state-of-the-art.

