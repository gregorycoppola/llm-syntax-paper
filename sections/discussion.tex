\label{sec:discussion}

\paragraph{Mixed Results as a Linguistic Annotator}
Past work has shown mixed results.

Past work {\em has} shown that {\em large language models} do {\em not} work as {\em zero-shot CoNLL parsers} (TODO: cite).

On the other hand, there also {\em has} been some important work that showed that llm's {\em can} in fact reliably put out labels that correspond to reality of syntactic judgmements (TODO: cite, zettlemoyer, other stuff).

So, the picture has been somewhat mixed.


\paragraph{Specific Targeted Focus}

Our interest here has been the task of {\em semantic parsing}.
Towards this end, there has been an emphasis on the parsing to structures that will support this.
Unlike the (TODO: cite Bulgarian girl), for example, we are not simply interested in whether or not arbitrary judgements work.
We are interested in the ones that are specifically related to syntactic parsing.
TODO: actually the Bulgarian girl paper was related to semantic parsing

Whereas others have sought perhaps to focus on the limitations of complex judgements, our focus has instead been on the question of finding simple judgements that the large language model {\em can} make.

Rather than looking for evidence of limitations---we want to find any glimmer of a reliable signal.

\paragraph{Contributions to Specific Knowledge about LLM's as Linguists}

We replicate and extend certain results.
Again, we are interested in signals that are most relevant to our task of syntactic parsing, for the purpose of semantic parsing.

The new results we provide are:

\begin{itemize}
    \item we show that POS tagging accuracy is high, and give some more results about that (TODO: check if this is true)
    \item we show that large language models can do well on {\em prepositional phrase attachment} a classic kind of amibiguity
    \item we show in focused part-of-speech tagging experiments that ``wrong'' part-of-speech tags relative to the CoNLL dataset are actually reasonable, and perhaps even right
    \item we show that the large language model can be used to get out-of-domain accuracy better than the CoNLL parser at prepositional phrase attachment
    \item we show that a large language model has differences from the CoNLL phrase-structure that might motivate a moving away from that
    \item we show early signals that a large language model can actually act as a basic phrase structure parser
\end{itemize}
